{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc09c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteraciones, acc train, acc test: \n",
      "400,    0.9838709677419355,    0.9259259259259259\n",
      "389,    0.967741935483871,    0.9814814814814815\n",
      "400,    1.0,    0.8518518518518519\n",
      "270,    0.967741935483871,    0.9074074074074074\n",
      "400,    0.9516129032258065,    0.9444444444444444\n",
      "389,    0.9758064516129032,    0.9259259259259259\n",
      "400,    0.9838709677419355,    0.9259259259259259\n",
      "321,    0.9838709677419355,    0.9444444444444444\n",
      "346,    0.967741935483871,    0.9259259259259259\n",
      "341,    0.9758064516129032,    0.9814814814814815\n",
      "372,    0.9838709677419355,    0.8888888888888888\n",
      "400,    1.0,    0.9444444444444444\n",
      "400,    0.9758064516129032,    0.9444444444444444\n",
      "400,    0.9838709677419355,    0.9444444444444444\n",
      "400,    0.9758064516129032,    0.9259259259259259\n",
      "-------------------------\n",
      "PROMEDIOS:\n",
      "iteraciones:  375.2  acc train:  0.9784946236559141  acc test:  0.9308641975308642\n"
     ]
    }
   ],
   "source": [
    "func_act = \"softmax\"\n",
    "func_costo = \"EC\"\n",
    "\n",
    "entrenamiento = 0.7\n",
    "alpha = 0.1\n",
    "#en costo poner 'ECM' o 'EC_binaria' o 'EC'\n",
    "\n",
    "################\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, metrics, model_selection\n",
    "\n",
    "import time\n",
    "#from matplotlib import pyplot as plt\n",
    "from matplotlib import pylab as plt\n",
    "from IPython import display\n",
    "\n",
    "from grafica import *\n",
    "from ClassRNMulticlase import RNMulticlase\n",
    "\n",
    "datos = pd.read_csv('../../Datos/Vinos.csv', sep=\";\")\n",
    "#datos\n",
    "#print(datos.Class.unique())\n",
    "\n",
    "reps = 15\n",
    "sumaAccTrain = 0\n",
    "sumaAccTest = 0\n",
    "sumaIteraciones = 0\n",
    "\n",
    "print(\"iteraciones, acc train, acc test: \")\n",
    "\n",
    "for rep in range(reps):\n",
    "    testeo = 1 - entrenamiento\n",
    "\n",
    "    X = np.array(datos.iloc[:, 1:])\n",
    "    T = np.array(datos['Class'])\n",
    "\n",
    "    enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "    T = enc.fit_transform(T.reshape(-1,1)).toarray()\n",
    "\n",
    "    #print(T)#hacemos una columna para cada clase posible\n",
    "    \n",
    "    X_train, X_test, T_train, T_test = model_selection.train_test_split(\n",
    "    X, T, test_size=testeo)\n",
    "\n",
    "    normalizador= preprocessing.StandardScaler() #media y desvío\n",
    "    X_train = normalizador.fit_transform(X_train)\n",
    "    X_test  = normalizador.transform(X_test)\n",
    "    \n",
    "    if (func_act == 'tanh'):\n",
    "        T_train = 2*T_train-1\n",
    "        T_test  = 2*T_test-1\n",
    "\n",
    "    rn = RNMulticlase(alpha=alpha, n_iter=400, cotaE=1e-06, FUN=func_act, COSTO=func_costo, random_state=None)\n",
    "    resul = rn.fit(X_train, T_train)\n",
    "    \n",
    "#     plt.plot(range(1, len(rn.errors_) + 1), rn.errors_, marker='o')\n",
    "#     plt.xlabel('Iteraciones')\n",
    "#     plt.ylabel(func_costo)\n",
    "#     plt.show()\n",
    "\n",
    "    iteraciones = len(rn.errors_)\n",
    "    sumaIteraciones += iteraciones\n",
    "    \n",
    "#     plt.plot(range(1, len(rn.accuracy_) + 1), rn.accuracy_, marker='o')\n",
    "#     plt.xlabel('Iteraciones')\n",
    "#     plt.ylabel('accuracy')\n",
    "#     plt.show()\n",
    "    \n",
    "    #-- accuracy en entrenamiento y testeo ---\n",
    "    acc_Train = rn.accuracy(X_train, T_train)\n",
    "    acc_Test = rn.accuracy(X_test, T_test)\n",
    "    \n",
    "    print(f\"{iteraciones},    {acc_Train},    {acc_Test}\")\n",
    "    \n",
    "    sumaAccTrain += acc_Train\n",
    "    sumaAccTest += acc_Test\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"PROMEDIOS:\")\n",
    "print(\"iteraciones: \",sumaIteraciones/reps, \" acc train: \", sumaAccTrain/reps, \" acc test: \", sumaAccTest/reps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce2219",
   "metadata": {},
   "source": [
    "# Resultados:\n",
    "para no perder tanto tiempo siempre uso alpha 0.2, entrenamiento del 70%, haciendo 15 iteraciones para cada variante. Todos los datos son el promedio de las 15 ejecuciones hechas con esa configuración\n",
    "\n",
    "|función activación|función costo|iteraciones|acc train|acc test|\n",
    "|---|---|---|---|---|\n",
    "|sigmoide|ecm|400|0.988|0.927\n",
    "|sigmoide|ec_bin|333.333|0.989|0.938\n",
    "|tanh|ecm|391.8|0.988|0.933\n",
    "|softmax|ec|375.2|0.978|0.931"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7a6bfb",
   "metadata": {},
   "source": [
    "# Conclusiones:\n",
    "la función sigmoide y tangencial no tienen mucha diferencia cuando ambas usan la función de costo de error mínimo cuadrado, pero la sigmoideal con error binario es lo que mejor funciona. Yo esperaba que al usar softmax los resultados se entrenen más rápido y que tengan una mejor precisión, pero parece que esto segundo no es así.\n",
    "La utilidad de usar softmax es que la suma de los resultados de predecir entre diferentes clases suma 1, no tiene porqué tener mejores resultados. Al igual que el ej anterior vemos que sigmoide se entrena más rápiod con ec_bin. Softmax permite que diga \"esta clase tiene X probabilidad de ser esta clase A\", esto no lo podemos hacer con las otras funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f5db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
