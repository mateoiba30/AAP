{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_train_score = 0\n",
    "sum_test_score = 0\n",
    "iteraciones = 10\n",
    "\n",
    "FunH = 'tanh'   # identity logistic tanh relu\n",
    "ocultas = (13)\n",
    "alfa = 0.01\n",
    "MAX_ITE = 2000\n",
    "\n",
    "import pandas as pd      # para trabajar con archivos de datos csv, excel, etc: https://pandas.pydata.org/docs/getting_started/tutorials.html\n",
    "import chardet           # para detectar la codificación de texto en archivos\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "nombre_archivo = '../Datos/Zoo.csv' # archivo de hojas\n",
    "\n",
    "#-- detectando la codificación de caracteres usada ----\n",
    "with open(nombre_archivo, 'rb') as f:\n",
    "    result = chardet.detect(f.read())  # or readline if the file is large\n",
    "\n",
    "# recupera el archivo en un objeto dataframe de pandas utilizando la codificación detectada\n",
    "df = pd.read_csv(nombre_archivo, encoding=result['encoding'])\n",
    "\n",
    "# %% separa atributos y clases\n",
    "X_raw = np.array(df.iloc[:,1:-1])  # recupera todas las columnas salvo la primera (es la clase)\n",
    "Y_raw = np.array(df.iloc[:,-1])    # recupera solo la última columna (es la clase)\n",
    "\n",
    "# Binarizador para convertir el nombre de la clase en one hot encoding\n",
    "binarizer = preprocessing.LabelBinarizer()\n",
    "\n",
    "# Binariza cada clase como una combinación de un 1 y 0s\n",
    "Y_raw = binarizer.fit_transform(Y_raw)\n",
    "# print('Las clases del dataset son :', binarizer.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1718645993456,
     "user": {
      "displayName": "Redes Neuronales",
      "userId": "11693180954775528178"
     },
     "user_tz": 180
    },
    "id": "31U4F4YICm74",
    "outputId": "7b72cc70-13c6-455c-8d5f-79bdd160429c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score iter 1: 1.0\n",
      "test score iter 1: 1.0\n",
      "train score iter 2: 1.0\n",
      "test score iter 2: 0.8064516129032258\n",
      "train score iter 3: 1.0\n",
      "test score iter 3: 0.9354838709677419\n",
      "train score iter 4: 1.0\n",
      "test score iter 4: 0.9354838709677419\n",
      "train score iter 5: 1.0\n",
      "test score iter 5: 0.9032258064516129\n",
      "train score iter 6: 1.0\n",
      "test score iter 6: 0.9354838709677419\n",
      "train score iter 7: 1.0\n",
      "test score iter 7: 0.9354838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mateo\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score iter 8: 1.0\n",
      "test score iter 8: 0.9032258064516129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mateo\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score iter 9: 1.0\n",
      "test score iter 9: 1.0\n",
      "train score iter 10: 1.0\n",
      "test score iter 10: 0.967741935483871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mateo\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(iteraciones):\n",
    "\n",
    "    # Separa ejemplos para enternamiento y testeo\n",
    "    TEST_SIZE = 0.3 # proporcion entre testeo entre entrenamiento y testeo\n",
    "    X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X_raw, Y_raw, test_size=TEST_SIZE)#, random_state=42)\n",
    "\n",
    "    # print('\\nDatos de Entrenamiento: %d   Datos de Testeo: %d' % (len(Y_train), len(Y_test) ))\n",
    "\n",
    "    # Escala los atributos de los ejemplo\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    #scaler = preprocessing.MinMaxScaler()\n",
    "    X_train  = scaler.fit_transform( X_train )\n",
    "    X_test   = scaler.transform( X_test )\n",
    "\n",
    "    modelo = MLPClassifier(max_iter=MAX_ITE, hidden_layer_sizes=ocultas, alpha=alfa,\n",
    "                           activation=FunH,\n",
    "#                            tol=0.0002, #esto es la tolerancia al fallo, todavía no lo vimos\n",
    "                           verbose=False).fit(X_train, Y_train)\n",
    "    #SKLEARN ELIGE entropía cruzada PARA USAR COMO FUNCIÓN DEL ERROR PARA MLPCLASSIFIER\n",
    "\n",
    "    #  ########### Medición del entrenamiento ######################\n",
    "    Y_pred = modelo.predict(X_train)\n",
    "    score = modelo.score(X_train, Y_train)\n",
    "\n",
    "    # \"invierte\" la transformacion binaria para obtener los nombres de las clases\n",
    "    Y_it = binarizer.inverse_transform(Y_train)\n",
    "    Y_pred_it = binarizer.inverse_transform(Y_pred)\n",
    "\n",
    "    # calculo manual del accuracy\n",
    "    # print('Efectividad: %6.2f%%' % (100*(Y_pred_it == Y_it).sum()/len(Y_it)) )\n",
    "    # print('      Score: %6.2f%%' % (score) )\n",
    "    print(f\"train score iter {i+1}: {score}\")\n",
    "    sum_train_score += score\n",
    "    # plt.plot(modelo.loss_curve_)\n",
    "    \n",
    "    #  ########### Medición del testeo ######################\n",
    "    Y_pred = modelo.predict(X_test)\n",
    "    score = modelo.score(X_test, Y_test)\n",
    "\n",
    "    # \"invierte\" la transformacion binaria para obtener los nombres de las clases\n",
    "    Y_it = binarizer.inverse_transform(Y_test)\n",
    "    Y_pred_it = binarizer.inverse_transform(Y_pred)\n",
    "\n",
    "    # calculo manual del accuracy\n",
    "    # print('Efectividad: %6.2f%%' % (100*(Y_pred_it == Y_it).sum()/len(Y_it)) )\n",
    "    # print('   R2 Score: %6.2f%%' % (score) )\n",
    "    print(f\"test score iter {i+1}: {score}\")\n",
    "    sum_test_score += score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train Score:   1.00%\n",
      "Avg test Score:   0.93%\n"
     ]
    }
   ],
   "source": [
    "print('Avg train Score: %6.2f%%' % (float(sum_train_score)/iteraciones ))\n",
    "print('Avg test Score: %6.2f%%' % (float(sum_test_score)/iteraciones ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados: \n",
    "## al principio usaba un max_iteraciones de 500, pero el modelo nunca convergía\n",
    "|capas ocultas|avg train score|avg test score|\n",
    "|---|---|---|\n",
    "|4|0.48|0.52|\n",
    "|8|0.83|0.76|\n",
    "## por este motivo empecé a usar un max iterations de 2000\n",
    "|capas ocultas|avg train score|avg test score|\n",
    "|---|---|---|\n",
    "|12|1|0.87|\n",
    "## como no estamos analizando imágenes pensé que era mejor dejar de usar relu para probar con tanh, la cual nos dio los siguientes resultados\n",
    "|capas ocultas|avg train score|avg test score|\n",
    "|---|---|---|\n",
    "|12|1|0.90|\n",
    "|15|1|0.94|\n",
    "|13|1|0.93|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1h9-ghQ8VXSPHLSG8Hkv8V3MqycXubDfN",
     "timestamp": 1667621061373
    },
    {
     "file_id": "1FV-Ydu5NBJ7DvGNfrlwMxfBHzXCqsO4A",
     "timestamp": 1667001788387
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": "16",
    "lenType": "16",
    "lenVar": "50"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
